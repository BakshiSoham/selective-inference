\documentclass{article}


\usepackage{graphicx,natbib}
\usepackage{../../Stats/LaTeX/mycommands}
\usepackage{amsmath,amssymb,amsthm,bm,enumerate}
\usepackage{latexsym,color,verbatim,minipage-marginpar,caption,multirow}

\begin{document}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

\renewcommand{\S}{\mathcal{S}}
\newcommand{\FDR}{\textnormal{FDR}}
\newcommand{\FCR}{\textnormal{FCR}}

\title{UMPU Interval Computation}
\maketitle

\newcommand{\cr}{\rho}

Let
\begin{equation}
  X\sim \phi(x-\mu)\1_{x\in S}, S\sub \R
\end{equation}
This is an exponential family with natural parameter $\mu$ and
sufficient statistic $X$, so the UMPU critical function $\cr$
for $H_0:\,\mu=0$ rejects for $X\notin (a,b)$ where
\begin{align}
  \E_0[\cr(X)] &= \alpha\\
  \E_0[X\cr(X)] &= \alpha\E_0 X
\end{align}



\section{Introduction}









In the curriculum of a typical introductory class on regression,
students are taught elegant and general tools for testing hypotheses
and constructing confidence intervals for the parameters of linear
models.  Later in the course, students are taught tools for
model selection.  If their professor is
sufficiently conscientious, the students are warned that essentially
all the inference tools previously presented are invalid unless the
investigator decides on a model before seeing the data.

In what sense are inferences after selection invalid?  Each of the
nominal intervals is {\em marginally valid} for its corresponding
parameter; that is,
\begin{equation}
  \P\left(\beta_{j,M} \in \left(\hat \beta_{j,M} - z(\alpha)
      \text{s.e.}(\hat\beta_{j,M}), \hat \beta_{j,M} + z(\alpha)
      \text{s.e.}(\hat\beta_{j,M})\right)\right) = 1-\alpha
\end{equation}

Here, we take up the serious issue of whether


Then, the
students are sent out into the world.

This state of affairs

Paragraph about widespread concern regarding validity of scientific
findings.  \citet{ioannidis}

Recently, \citet{berk2013valid} introduced an important innovation
addressing this issue: a Scheff\'{e}-like procedure for valid
inference after an {\em arbitrary} model selection procedure, with a
guarantee of {\em simultaneous validity} for confidence intervals
constructed  or hypothesis tests performed after selection.

Finally, we discuss

\subsection{Notation and Problem Setting}

We observe a vector $y \sim N_n(\mu, \Sigma)$, with known covariance
and unknown mean (the procedure can be generalized to a multivariate $t$
response, if an unbiased Wishart estimate of $\Sigma$ is available).

After seeing the data, we construct a confidence interval or perform a
hypothesis test for one or
more {\em random} linear functions $\eta^T\mu$.  Concretely, the
$\eta^T\mu$ will often take the form of linear regression
coefficients for a selected model.  If $X\in \R^{n\times p}$ and
$M\sub\{1,\ldots, p\}$, write
\begin{align}
  \beta_{j,M} &= e_j (X_M^TX_M)^{-1}X_M^T \mu
\end{align}
so that the corresponding $\eta$ is $\eta_{j,M} =
e_j(X_M^TX_M)^{-1}X_M^T$. \red{$e_j$ is bad notation, what if
  $M=\{2,3\}$?}
In general, we have some discrete set $H = \{\eta_k\}_{k=1}^K$ of size
$K\leq \infty$ of candidate linear functions, a few of which we will
adaptively flag as interesting.

A {\em selection procedure} $\S(y)\sub H$ is any discrete data-dependent
decision about which $\eta$ are interesting.  Then, we perform
inference on each $\eta\in \S$.
For example, we could perform five steps of forward stepwise
regression and construct confidence intervals for all six regression
coefficients in the final selected model.

A {\em polytope selection procedure} is one for which the partition is
.  We show in Section~\ref{sec:polytope}
that this class

\subsection{The False Discovery Rate and False Coverage Statement Rate}



\citet{benjamini2005} define a similar notion of error rate for
confidence intervals, recognizing that confidence intervals after
selection face multiple comparisons problems akin to those of
hypothesis testing.

Suppose that, upon
seeing our data, we construct $R$ confidence intervals for $R$
parameters, in general chosen randomly among many candidate
parameters.  Let $V$ be the number of intervals not covering their
parameters.  Then \citet{benjamini2005} define the {\em False
  Coverage-Statement Rate} (FCR) as
\begin{equation}
  \FCR = \E\left(\frac{V}{R\vee 1}\right),
\end{equation}
by analogy with the better-known {\em False Discovery Rate}.

Our method for constructing confidence intervals generalizes the
construction of \citet{weinstein2012confidence} to regression settings.

Conditional coverage guarantees of level $\alpha$ are sufficient to
control the FCR:
\begin{proposition}
  Any procedure which selects
\end{proposition}

\subsection{Conditional Inference}


\section*{Acknowledgements}


\bibliographystyle{plainnat}
\bibliography{../../LaTex/biblio}

\end{document}
